odinson {

  # all data related to odinson is stored here
  dataDir = ${user.home}/data/odinson

  # path to text files
  textDir = ${odinson.dataDir}/text

  # path to serialized documents
  docsDir = ${odinson.dataDir}/docs

  # path to lucene index
  indexDir = ${odinson.dataDir}/index

  # how many search results to display per page
  pageSize = 20

  # the token attribute to use for display.
  # NOTE: this must be **stored** in the current index in order for it to be retrievable.
  # By default, this should be "raw"
  displayField = "raw"

  # should a precise totalHits be calculated per query
  computeTotalHits = true

  state {
    provider = "memory" // "sql" "file" "memory"

    memory {
      persistOnClose = false
      stateDir = ${odinson.dataDir}/state
    }

    sql {
      persistOnClose = false
      // See http://www.h2database.com/html/features.html.
      url = "jdbc:h2:mem:odinson" // memory
      // url = "jdbc:h2:file:./odinson.db" // file
      persistFile = "./state.sql"
    }

  }

  compiler {

    # fields available per token
    allTokenFields = [
      ${odinson.index.rawTokenField},
      ${odinson.index.wordTokenField},
      ${odinson.index.normalizedTokenField},
      ${odinson.index.lemmaTokenField},
      ${odinson.index.posTagTokenField},
      ${odinson.index.chunkTokenField},
      ${odinson.index.entityTokenField},
      ${odinson.index.incomingTokenField},
      ${odinson.index.outgoingTokenField},
    ]

    # the token field to be used when none is specified
    defaultTokenField = ${odinson.index.normalizedTokenField}

    dependenciesField = ${odinson.index.dependenciesField}

    incomingTokenField = ${odinson.index.incomingTokenField}

    outgoingTokenField = ${odinson.index.outgoingTokenField}

    # if we are using the normalizedTokenField as the default
    # then we should casefold the queries to the default field
    # so that they match
    aggressiveNormalizationToDefaultField = true
  }

  index {

    # list of document/sentence fields to store in index, **must** include the displayField
    storedFields = [
      ${odinson.displayField},
      ${odinson.index.lemmaTokenField}
    ]

    # the raw token
    rawTokenField = raw

    # the word itself
    wordTokenField = word

    # a normalized version of the token
    normalizedTokenField = norm

    # the normalized field will include values from the following fields
    addToNormalizedField = [
      ${odinson.index.rawTokenField},
      ${odinson.index.wordTokenField},
    ]

    # token attribute fields
    lemmaTokenField = lemma

    posTagTokenField = tag

    chunkTokenField = chunk

    entityTokenField = entity

    incomingTokenField = incoming

    outgoingTokenField = outgoing

    dependenciesField = dependencies

    maxNumberOfTokensPerSentence = 100

    // Sometimes there are tokens in documents which are incompatible with the way we use Lucene.
    // In those cases, we replace the token with this character (default: ï¿½).
    invalidCharacterReplacement = "\ufffd"

    incremental = false
    refreshMs = -1
  }

}
